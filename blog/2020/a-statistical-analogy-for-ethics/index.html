<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Statistical Analogy for Ethics | Shuvom Sadhuka </title> <meta name="author" content="Shuvom Sadhuka"> <meta name="description" content="Reasoning about ethics via an analogy"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%8C&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shuvom-s.github.io/blog/2020/a-statistical-analogy-for-ethics/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Shuvom Sadhuka </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">A Statistical Analogy for Ethics</h1> <p class="post-meta"> Created in May 10, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> statistics</a>   <a href="/blog/tag/ethics"> <i class="fa-solid fa-hashtag fa-sm"></i> ethics</a>   <a href="/blog/tag/law"> <i class="fa-solid fa-hashtag fa-sm"></i> law</a>   ·   <a href="/blog/category/blog-posts"> <i class="fa-solid fa-tag fa-sm"></i> blog-posts</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Note: This post was originally published on <a href="https://randomquadwalks.com/2020/05/10/a-statistical-analogy-for-ethics/" rel="external nofollow noopener" target="_blank">my old blog</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ethics-480.webp 480w,/assets/img/ethics-800.webp 800w,/assets/img/ethics-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/ethics.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>I’ve grown a little frustrated in how morality and moral law are often misused in public debate.</p> <p>To start, let’s consider what a moral framework entails. In some sense, moral philosophy is merely a model to determine whether an action is right or wrong. Different frameworks specify exact models for understanding right and wrong; some consider the output a spectrum; others consider it a binary; others even say it’s impossible to interpret any output.</p> <p>It’s important to note that the <em>model itself</em> is distinct from the <em>political legitimacy</em> of the model (i.e. how well a model is accepted as legitimate by the government). Our federal laws, for example, realize a philosophical model with strong political legitimacy, but federal laws are amended and changed when that model does not coincide with some other, “truer” philosophical framework.</p> <p>This notion may seem excruciatingly obvious, but you’ll frequently hear accusations of setting “arbitrary moral guidelines” or appeals to the constitution because it was “willed by the people.” These attacks only undermine the political legitimacy of the chosen moral framework, not the internal validity.</p> <p>It’s equally frustrating when critics of a certain moral framework find tiny, irrelevant exceptions as conclusive disproofs. Just as we wouldn’t discard a machine learning model because of occasional errors, we shouldn’t discard philosophical frameworks because we can find exceptions to them.</p> <p>Instead, a more convincing critique takes issue with the assumptions made by the model, similar to how we’d criticize a poorly applied machine learning method.</p> <p>Moreover, any philosophical framework necessarily makes simplifying assumptions and prescribes categorical laws. Utilitarians may shake their fists at me and argue that utilitarianism maximizes good, but I would argue that any framework attempts to maximize good, so this naive utilitarianism fails to prescribe action. Without an exact set of ascribed utilities to actions, I cannot guide my action to “maximize good.” And once you give me this set of weights, it’s almost certainly possible to find a counterexample.</p> <p>Reaching moral skepticism from these observations is even more preposterous: that would be equivalent to saying “because physics is sometimes contradictory, we should discard our entire conception of the universe.”</p> <p>To see how all of these pieces fit together, let’s imagine morality as a sort of mathematical problem. Imagine we have a set of (many, many) axes which contextualize each action we take (e.g. the time of the action, who is there, their positions in society, etc.—every possible degree-of-freedom of a given action). Each action we take is a dot in this large grid, and we wish to classify these dots as moral (“1”) or immoral (“0”) decisions (or a regression problem if you believe morality is a spectrum). There exists a true classification (although this is debatable), and we want to find a model that best approximates this true classification.</p> <p>We can, therefore, think of categorical laws such as “never steal” as analogous to simpler models like linear regression. We can add conditions to increase model complexity, such as “never steal unless the person is six feet tall and has seven kids.” More generally, model complexity, bias, and variance in machine learning can be analogized to moral frameworks:</p> <ol> <li> <p><strong>Model Complexity</strong>: As we increase model complexity, we lose interpretability, which is especially concerning in moral philosophy (which serve as interpretable guides to action), so we should penalize convoluted moral frameworks.</p> </li> <li> <p><strong>Interpretability</strong> Taken to an extreme, we can have vague and uninterpretable moral models, which, while perhaps technically “correct,” could be very “noisy” and uninterpretable, paralyzing action. Many formulations of utilitarianism fall under this umbrella, in which someone blindly asserts that the best thing to do is to do the most good and then quantifies some metric like maximizing total happiness. Absent a concrete method to achieve this ideal, utilitarianism can be used to justify almost any policy with some set of weights. Think about it: when is the last time a politician made an argument and didn’t invoke some form of “everyone will be better off?” Instead, if we trade some model complexity for categorical laws (which international law aims to do, for example), we may often achieve better results, even by the utilitarian’s own metrics, similar to how we often aim to achieve the optimal “tradeoff” between bias and variance in selecting machine learning models. Perhaps going down this path may lead one to <a href="https://en.wikipedia.org/wiki/Rule_utilitarianism" rel="external nofollow noopener" target="_blank">rule utilitarianism</a>.</p> </li> <li> <p><strong>Bias and Variance</strong>: While simple moral models may have high bias (i.e. inaccurate in many scenarios), complex moral models will have higher variance as they paralyze action. For example, many religious texts have complex moral guidelines, so we defer the interpretation to our denomination and priests, yielding higher model variance. On the other hand, simple moral guidelines like the Ten Commandments might incur significant contradictions, but are far more actionable.</p> </li> </ol> <p>While small and relatively trivial, this example illustrates how we can cross-apply other fields to guide understanding of ethical systems.</p> <p>It’s not a secret that different fields often employ their own jargon, which makes their ideas (slightly) inaccessible to other fields, but connecting ideas across fields (e.g. bias-variance tradeoff and moral philosophy) can illuminate how the same logic often underlies different results.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/reading-list/">Reading List</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/measuring-entropy/">Measuring Entropy</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/advice-on-applying-to-fellowships/">Fellowship Applications</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/my-thoughts/">A running list of writing ideas</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/overcoming-the-false-tradeoff-in-genomics/">Overcoming the False Trade-off in Genomics</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'shuvom-s/shuvom-s.github.io',
        'data-repo-id': 'R_kgDONxLE6Q',
        'data-category': 'General',
        'data-category-id': 'DIC_kwDONxLE6c4Cm6ys',
        'data-mapping': 'pathname',
        'data-strict': '0',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Shuvom Sadhuka. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>